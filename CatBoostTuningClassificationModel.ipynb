{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -q numpy pandas catboost hyperopt scikit-learn frozendict matplotlib\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost version 0.16.4\n",
      "NumPy version 1.16.4\n",
      "Pandas version 0.24.2\n"
     ]
    }
   ],
   "source": [
    "#Initial code used from https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/\n",
    " # and parameter search from https://effectiveml.com/using-grid-search-to-optimise-catboost-parameters.html\n",
    "\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "import catboost.utils as cbu\n",
    "import hyperopt\n",
    "import sys\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "from frozendict import frozendict\n",
    "%matplotlib inline\n",
    "\n",
    "# print module versions for reproducibility\n",
    "print('CatBoost version {}'.format(cb.__version__))\n",
    "print('NumPy version {}'.format(np.__version__))\n",
    "print('Pandas version {}'.format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>preapproval</th>\n",
       "      <th>msa_md</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>...</th>\n",
       "      <th>dummy</th>\n",
       "      <th>log(x+1)_loan_amount</th>\n",
       "      <th>log(x+1)_LTI</th>\n",
       "      <th>log(x+1)_applicant_income</th>\n",
       "      <th>log(x+1)_population</th>\n",
       "      <th>log(x+1)_minority_population_pct</th>\n",
       "      <th>log(x+1)_ffiecmedian_family_income</th>\n",
       "      <th>log(x+1)_number_of_owner-occupied_units</th>\n",
       "      <th>log(x+1)_number_of_1_to_4_family_units</th>\n",
       "      <th>pwr10_tract_to_msa_md_income_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>1.365241</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>8.732950</td>\n",
       "      <td>3.811761</td>\n",
       "      <td>11.011869</td>\n",
       "      <td>6.575076</td>\n",
       "      <td>7.879670</td>\n",
       "      <td>1.174877e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3</td>\n",
       "      <td>369</td>\n",
       "      <td>52</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.187386</td>\n",
       "      <td>1.416534</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>8.661294</td>\n",
       "      <td>2.827609</td>\n",
       "      <td>10.911847</td>\n",
       "      <td>7.392032</td>\n",
       "      <td>7.653969</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>306</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.099866</td>\n",
       "      <td>1.233387</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>8.715224</td>\n",
       "      <td>4.131480</td>\n",
       "      <td>11.123137</td>\n",
       "      <td>6.634633</td>\n",
       "      <td>6.955593</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>47</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.049856</td>\n",
       "      <td>0.906721</td>\n",
       "      <td>4.663439</td>\n",
       "      <td>8.805075</td>\n",
       "      <td>1.980450</td>\n",
       "      <td>11.270089</td>\n",
       "      <td>7.613819</td>\n",
       "      <td>7.740664</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.723585</td>\n",
       "      <td>1.666909</td>\n",
       "      <td>4.276666</td>\n",
       "      <td>8.814776</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>11.052096</td>\n",
       "      <td>7.289611</td>\n",
       "      <td>7.521859</td>\n",
       "      <td>1.408375e+19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  loan_type  property_type  loan_purpose  occupancy  loan_amount  \\\n",
       "0       0          3              1             1          1         70.0   \n",
       "1       1          1              1             3          1        178.0   \n",
       "2       2          2              1             3          1        163.0   \n",
       "3       3          1              1             1          1        155.0   \n",
       "4       4          1              1             1          1        305.0   \n",
       "\n",
       "   preapproval  msa_md  state_code  county_code  ...  dummy  \\\n",
       "0            3      18          37          246  ...    1.0   \n",
       "1            3     369          52          299  ...    1.0   \n",
       "2            3      16          10          306  ...    1.0   \n",
       "3            1     305          47          180  ...    1.0   \n",
       "4            3      24          37           20  ...    1.0   \n",
       "\n",
       "   log(x+1)_loan_amount  log(x+1)_LTI  log(x+1)_applicant_income  \\\n",
       "0              4.262680      1.365241                   3.218876   \n",
       "1              5.187386      1.416534                   4.060443   \n",
       "2              5.099866      1.233387                   4.219508   \n",
       "3              5.049856      0.906721                   4.663439   \n",
       "4              5.723585      1.666909                   4.276666   \n",
       "\n",
       "   log(x+1)_population  log(x+1)_minority_population_pct  \\\n",
       "0             8.732950                          3.811761   \n",
       "1             8.661294                          2.827609   \n",
       "2             8.715224                          4.131480   \n",
       "3             8.805075                          1.980450   \n",
       "4             8.814776                          4.615121   \n",
       "\n",
       "   log(x+1)_ffiecmedian_family_income  \\\n",
       "0                           11.011869   \n",
       "1                           10.911847   \n",
       "2                           11.123137   \n",
       "3                           11.270089   \n",
       "4                           11.052096   \n",
       "\n",
       "   log(x+1)_number_of_owner-occupied_units  \\\n",
       "0                                 6.575076   \n",
       "1                                 7.392032   \n",
       "2                                 6.634633   \n",
       "3                                 7.613819   \n",
       "4                                 7.289611   \n",
       "\n",
       "   log(x+1)_number_of_1_to_4_family_units  pwr10_tract_to_msa_md_income_pct  \n",
       "0                                7.879670                      1.174877e+17  \n",
       "1                                7.653969                      1.000000e+20  \n",
       "2                                6.955593                      1.000000e+20  \n",
       "3                                7.740664                      1.000000e+20  \n",
       "4                                7.521859                      1.408375e+19  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load already prepared training dataset, display shape, & explore first 10 rows of Pandas data frame\n",
    "\n",
    "train_set = pd.read_csv('progressData/LoanTrain_Clean_2019-08-12-A2e2a.csv')\n",
    "print(train_set.shape)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>preapproval</th>\n",
       "      <th>msa_md</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>...</th>\n",
       "      <th>RaceGroup</th>\n",
       "      <th>log(x+1)_loan_amount</th>\n",
       "      <th>log(x+1)_LTI</th>\n",
       "      <th>log(x+1)_applicant_income</th>\n",
       "      <th>log(x+1)_population</th>\n",
       "      <th>log(x+1)_minority_population_pct</th>\n",
       "      <th>log(x+1)_ffiecmedian_family_income</th>\n",
       "      <th>log(x+1)_number_of_owner-occupied_units</th>\n",
       "      <th>log(x+1)_number_of_1_to_4_family_units</th>\n",
       "      <th>pwr10_tract_to_msa_md_income_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>276</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>0.937682</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>8.753056</td>\n",
       "      <td>4.103238</td>\n",
       "      <td>11.154678</td>\n",
       "      <td>7.536364</td>\n",
       "      <td>7.787797</td>\n",
       "      <td>2.157051e+19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>20</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.533389</td>\n",
       "      <td>1.210494</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>7.813592</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>11.086962</td>\n",
       "      <td>6.854355</td>\n",
       "      <td>7.102499</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.602119</td>\n",
       "      <td>1.184456</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>8.512382</td>\n",
       "      <td>3.176177</td>\n",
       "      <td>11.120105</td>\n",
       "      <td>7.190676</td>\n",
       "      <td>7.469654</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>2</td>\n",
       "      <td>376</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.192957</td>\n",
       "      <td>1.622982</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>8.475538</td>\n",
       "      <td>3.423481</td>\n",
       "      <td>10.964173</td>\n",
       "      <td>7.263330</td>\n",
       "      <td>7.476472</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>254</td>\n",
       "      <td>48</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>0.753772</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>8.565412</td>\n",
       "      <td>1.809927</td>\n",
       "      <td>11.056162</td>\n",
       "      <td>7.281386</td>\n",
       "      <td>7.646354</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  loan_type  property_type  loan_purpose  occupancy  loan_amount  \\\n",
       "0       0          2              1             3          1        115.0   \n",
       "1       1          1              1             1          1        252.0   \n",
       "2       2          1              1             1          1        270.0   \n",
       "3       3          2              1             1          1        179.0   \n",
       "4       4          2              1             1          1         36.0   \n",
       "\n",
       "   preapproval  msa_md  state_code  county_code  ...  RaceGroup  \\\n",
       "0            3     101          16          276  ...          5   \n",
       "1            2      87          20           68  ...          5   \n",
       "2            1      -1          -1           -1  ...          1   \n",
       "3            2     376          20           11  ...          2   \n",
       "4            2     254          48          156  ...          6   \n",
       "\n",
       "   log(x+1)_loan_amount  log(x+1)_LTI  log(x+1)_applicant_income  \\\n",
       "0              4.753590      0.937682                   4.317488   \n",
       "1              5.533389      1.210494                   4.682131   \n",
       "2              5.602119      1.184456                   4.787492   \n",
       "3              5.192957      1.622982                   3.806662   \n",
       "4              3.610918      0.753772                   3.496508   \n",
       "\n",
       "   log(x+1)_population  log(x+1)_minority_population_pct  \\\n",
       "0             8.753056                          4.103238   \n",
       "1             7.813592                          2.202765   \n",
       "2             8.512382                          3.176177   \n",
       "3             8.475538                          3.423481   \n",
       "4             8.565412                          1.809927   \n",
       "\n",
       "   log(x+1)_ffiecmedian_family_income  \\\n",
       "0                           11.154678   \n",
       "1                           11.086962   \n",
       "2                           11.120105   \n",
       "3                           10.964173   \n",
       "4                           11.056162   \n",
       "\n",
       "   log(x+1)_number_of_owner-occupied_units  \\\n",
       "0                                 7.536364   \n",
       "1                                 6.854355   \n",
       "2                                 7.190676   \n",
       "3                                 7.263330   \n",
       "4                                 7.281386   \n",
       "\n",
       "   log(x+1)_number_of_1_to_4_family_units  pwr10_tract_to_msa_md_income_pct  \n",
       "0                                7.787797                      2.157051e+19  \n",
       "1                                7.102499                      1.000000e+20  \n",
       "2                                7.469654                      1.000000e+20  \n",
       "3                                7.476472                      1.000000e+20  \n",
       "4                                7.646354                      1.000000e+20  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load test data previously prepared in data preparation step.\n",
    "\n",
    "test_set = pd.read_csv('progressData/LoanTest_Clean_2019-08-12-A2w2a.csv')\n",
    "print(test_set.shape)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          loan_type\n",
      "accepted           \n",
      "0            249886\n",
      "1            250114\n"
     ]
    }
   ],
   "source": [
    "# Testing for Class Imbalance by Examining Classes where label= accepted\n",
    " # Unequal numbers of cases for the categories of labels, which can seriously bias the training of classifier alogrithms \n",
    " #  higher error rate for the minority class. This should be tested for before training any model.   \n",
    "\n",
    "train_set_counts = train_set[['loan_type','accepted']].groupby('accepted').count()\n",
    "print(train_set_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                                       int64\n",
       "loan_type                                    int64\n",
       "property_type                                int64\n",
       "loan_purpose                                 int64\n",
       "occupancy                                    int64\n",
       "loan_amount                                float64\n",
       "preapproval                                  int64\n",
       "msa_md                                       int64\n",
       "state_code                                   int64\n",
       "county_code                                  int64\n",
       "applicant_ethnicity                          int64\n",
       "applicant_race                               int64\n",
       "applicant_sex                                int64\n",
       "applicant_income                           float64\n",
       "population                                 float64\n",
       "minority_population_pct                    float64\n",
       "ffiecmedian_family_income                  float64\n",
       "tract_to_msa_md_income_pct                 float64\n",
       "number_of_owner-occupied_units             float64\n",
       "number_of_1_to_4_family_units              float64\n",
       "lender                                       int64\n",
       "co_applicant                                  bool\n",
       "accepted                                     int64\n",
       "LTI                                        float64\n",
       "CountyGroup                                float64\n",
       "LenderGroup                                  int64\n",
       "RaceGroup                                    int64\n",
       "dummy                                      float64\n",
       "log(x+1)_loan_amount                       float64\n",
       "log(x+1)_LTI                               float64\n",
       "log(x+1)_applicant_income                  float64\n",
       "log(x+1)_population                        float64\n",
       "log(x+1)_minority_population_pct           float64\n",
       "log(x+1)_ffiecmedian_family_income         float64\n",
       "log(x+1)_number_of_owner-occupied_units    float64\n",
       "log(x+1)_number_of_1_to_4_family_units     float64\n",
       "pwr10_tract_to_msa_md_income_pct           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training data types\n",
    "\n",
    "train_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                                       int64\n",
       "loan_type                                    int64\n",
       "property_type                                int64\n",
       "loan_purpose                                 int64\n",
       "occupancy                                    int64\n",
       "loan_amount                                float64\n",
       "preapproval                                  int64\n",
       "msa_md                                       int64\n",
       "state_code                                   int64\n",
       "county_code                                  int64\n",
       "applicant_ethnicity                          int64\n",
       "applicant_race                               int64\n",
       "applicant_sex                                int64\n",
       "applicant_income                           float64\n",
       "population                                 float64\n",
       "minority_population_pct                    float64\n",
       "ffiecmedian_family_income                  float64\n",
       "tract_to_msa_md_income_pct                 float64\n",
       "number_of_owner-occupied_units             float64\n",
       "number_of_1_to_4_family_units              float64\n",
       "lender                                       int64\n",
       "co_applicant                                  bool\n",
       "LTI                                        float64\n",
       "CountyGroup                                float64\n",
       "LenderGroup                                  int64\n",
       "RaceGroup                                    int64\n",
       "log(x+1)_loan_amount                       float64\n",
       "log(x+1)_LTI                               float64\n",
       "log(x+1)_applicant_income                  float64\n",
       "log(x+1)_population                        float64\n",
       "log(x+1)_minority_population_pct           float64\n",
       "log(x+1)_ffiecmedian_family_income         float64\n",
       "log(x+1)_number_of_owner-occupied_units    float64\n",
       "log(x+1)_number_of_1_to_4_family_units     float64\n",
       "pwr10_tract_to_msa_md_income_pct           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check test data types\n",
    "\n",
    "test_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a training set for modeling and validation set to check model performance\n",
    "\n",
    "\n",
    "train_set = train_set.drop('accepted', axis=1) # remove labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                                       int64\n",
       "loan_type                                    int64\n",
       "property_type                                int64\n",
       "loan_purpose                                 int64\n",
       "occupancy                                    int64\n",
       "loan_amount                                float64\n",
       "preapproval                                  int64\n",
       "msa_md                                       int64\n",
       "state_code                                   int64\n",
       "county_code                                  int64\n",
       "applicant_ethnicity                          int64\n",
       "applicant_race                               int64\n",
       "applicant_sex                                int64\n",
       "applicant_income                           float64\n",
       "population                                 float64\n",
       "minority_population_pct                    float64\n",
       "ffiecmedian_family_income                  float64\n",
       "tract_to_msa_md_income_pct                 float64\n",
       "number_of_owner-occupied_units             float64\n",
       "number_of_1_to_4_family_units              float64\n",
       "lender                                       int64\n",
       "co_applicant                                  bool\n",
       "LTI                                        float64\n",
       "CountyGroup                                float64\n",
       "LenderGroup                                  int64\n",
       "RaceGroup                                    int64\n",
       "dummy                                      float64\n",
       "log(x+1)_loan_amount                       float64\n",
       "log(x+1)_LTI                               float64\n",
       "log(x+1)_applicant_income                  float64\n",
       "log(x+1)_population                        float64\n",
       "log(x+1)_minority_population_pct           float64\n",
       "log(x+1)_ffiecmedian_family_income         float64\n",
       "log(x+1)_number_of_owner-occupied_units    float64\n",
       "log(x+1)_number_of_1_to_4_family_units     float64\n",
       "pwr10_tract_to_msa_md_income_pct           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReCheck training data types\n",
    "\n",
    "train_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 20, 21, 24, 25])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, youâ€™ll see that we will only identify categorical variables. We will not perform any preprocessing steps for \n",
    " # categorical variables:\n",
    "\n",
    "categorical_features_indices = np.where(train_set.dtypes != np.float)[0]\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert datasets to numpy arrays\n",
    " # Load training labels\n",
    "\n",
    "train_set = np.array(train_set)\n",
    "test_set = np.array(test_set)\n",
    "\n",
    "l = pd.read_csv('data/train_labels.csv')\n",
    "labels = np.array(l['accepted'])\n",
    "print(labels.shape)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check labels\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a training set for modeling and validation set to check model performance\n",
    "\n",
    "nr.seed(1115)   # Randomly sample cases to create independent training & test data\n",
    "indx = range(train_set.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 150000)\n",
    "x_train = train_set[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "x_validation = train_set[indx[1],:]\n",
    "y_validation = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Check validation set\n",
    "\n",
    "print(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction set\n",
    "\n",
    "x_predict = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Check prediction set\n",
    "\n",
    "print(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLClassifierObjective(object):\n",
    "    def __init__(self, dataset, const_params, fold_count):\n",
    "        self._dataset = dataset\n",
    "        self._const_params = const_params.copy()\n",
    "        self._fold_count = fold_count\n",
    "        self._evaluated_count = 0\n",
    "        \n",
    "    def _to_catboost_params(self, hyper_params):\n",
    "        return {\n",
    "            'learning_rate': hyper_params['learning_rate'],\n",
    "            'depth': hyper_params['depth'],\n",
    "            'l2_leaf_reg': hyper_params['l2_leaf_reg']}\n",
    "    \n",
    "    # hyperopt optimizes an objective using `__call__` method (e.g. by doing \n",
    "    # `foo(hyper_params)`), so we provide one\n",
    "    def __call__(self, hyper_params):\n",
    "        # join hyper-parameters provided by hyperopt with hyper-parameters \n",
    "        # provided by the user\n",
    "        params = self._to_catboost_params(hyper_params)\n",
    "        params.update(self._const_params)\n",
    "        \n",
    "        print('evaluating params={}'.format(params), file=sys.stdout)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # we use cross-validation for objective evaluation, to avoid overfitting\n",
    "        scores = cb.cv(\n",
    "            pool=self._dataset,\n",
    "            params=params,\n",
    "            fold_count=self._fold_count,\n",
    "            partition_random_seed=20181224,\n",
    "            verbose=False)\n",
    "        \n",
    "        # scores returns a dictionary with mean and std (per-fold) of metric \n",
    "        # value for each cv iteration, we choose minimal value of objective \n",
    "        # mean (though it will be better to choose minimal value among all folds)\n",
    "        # because noise is additive\n",
    "        min_mean_auc = np.min(scores['test-AUC-mean'])\n",
    "        print('evaluated score={}'.format(min_mean_auc), file=sys.stdout)\n",
    "        \n",
    "        self._evaluated_count += 1\n",
    "        print('evaluated {} times'.format(self._evaluated_count), file=sys.stdout)\n",
    "        \n",
    "        # negate because hyperopt minimizes the objective\n",
    "        return {'loss': -min_mean_auc, 'status': hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyper_params(dataset, const_params, max_evals=100):    \n",
    "    # we are going to optimize these three parameters, though there are a lot more of them (see CatBoost docs)\n",
    "    parameter_space = {\n",
    "        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.2, 1.0),\n",
    "        'depth': hyperopt.hp.randint('depth', 7),\n",
    "        'l2_leaf_reg': hyperopt.hp.uniform('l2_leaf_reg', 1, 10)}\n",
    "    objective = HLClassifierObjective(dataset=dataset, const_params=const_params, fold_count=6)\n",
    "    trials = hyperopt.Trials()\n",
    "    best = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.rand.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.RandomState(seed=20181224))\n",
    "    return best\n",
    "\n",
    "def train_best_model(X, y, const_params, max_evals=100, use_default=False):\n",
    "    # convert pandas.DataFrame to catboost.Pool to avoid converting it on each \n",
    "    # iteration of hyper-parameters optimization\n",
    "    dataset = cb.Pool(X, y, cat_features=categorical_features_indices)\n",
    "    \n",
    "    if use_default:\n",
    "        # pretrained optimal parameters\n",
    "        best = {\n",
    "            'learning_rate': 0.4234185321620083, \n",
    "            'depth': 5, \n",
    "            'l2_leaf_reg': 9.464266235679002}\n",
    "    else:\n",
    "        best = find_best_hyper_params(dataset, const_params, max_evals=max_evals)\n",
    "            \n",
    "    # merge subset of hyper-parameters provided by hyperopt with hyper-parameters \n",
    "    # provided by the user\n",
    "    hyper_params = best.copy()\n",
    "    hyper_params.update(const_params)\n",
    "    \n",
    "    # drop `use_best_model` because we are going to use entire dataset for \n",
    "    # training of the final model\n",
    "    hyper_params.pop('use_best_model', None)\n",
    "    \n",
    "    model = cb.CatBoostClassifier(**hyper_params)\n",
    "    model.fit(dataset, verbose=False)\n",
    "    \n",
    "    return model, hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating params={'learning_rate': 0.8370106458894697, 'depth': 0, 'l2_leaf_reg': 8.835837790286535, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.5                                 \n",
      "evaluated 1 times                                   \n",
      "evaluating params={'learning_rate': 0.8414600898588487, 'depth': 3, 'l2_leaf_reg': 3.841780975474402, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7191331646763076                                \n",
      "evaluated 2 times                                                 \n",
      "evaluating params={'learning_rate': 0.4234185321620083, 'depth': 5, 'l2_leaf_reg': 9.464266235679002, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                               \n",
      "evaluated 3 times                                                                \n",
      "evaluating params={'learning_rate': 0.22471545632474588, 'depth': 3, 'l2_leaf_reg': 7.1682035345674, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7191331646763076                                               \n",
      "evaluated 4 times                                                                \n",
      "evaluating params={'learning_rate': 0.4007448994237649, 'depth': 5, 'l2_leaf_reg': 9.166597045734488, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                               \n",
      "evaluated 5 times                                                                \n",
      "evaluating params={'learning_rate': 0.6035795774443979, 'depth': 1, 'l2_leaf_reg': 6.57277845681401, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.6594692097881453                                               \n",
      "evaluated 6 times                                                                \n",
      "evaluating params={'learning_rate': 0.34665652413917175, 'depth': 5, 'l2_leaf_reg': 4.627187180193483, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                               \n",
      "evaluated 7 times                                                                \n",
      "evaluating params={'learning_rate': 0.7290697164191682, 'depth': 2, 'l2_leaf_reg': 5.9053685596093874, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                \n",
      "evaluated 8 times                                                                \n",
      "evaluating params={'learning_rate': 0.46610105978348887, 'depth': 2, 'l2_leaf_reg': 6.531608540940916, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                \n",
      "evaluated 9 times                                                                \n",
      "evaluating params={'learning_rate': 0.6652303888271369, 'depth': 5, 'l2_leaf_reg': 6.706159252357066, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                               \n",
      "evaluated 10 times                                                               \n",
      "evaluating params={'learning_rate': 0.8903978509893837, 'depth': 0, 'l2_leaf_reg': 5.966611099029412, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.5                                                               \n",
      "evaluated 11 times                                                                \n",
      "evaluating params={'learning_rate': 0.662529025136881, 'depth': 5, 'l2_leaf_reg': 8.583949294731982, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                \n",
      "evaluated 12 times                                                                \n",
      "evaluating params={'learning_rate': 0.8626290632298594, 'depth': 4, 'l2_leaf_reg': 5.857082940614299, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                \n",
      "evaluated 13 times                                                                \n",
      "evaluating params={'learning_rate': 0.7048806778933194, 'depth': 2, 'l2_leaf_reg': 6.130033478034561, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                 \n",
      "evaluated 14 times                                                                \n",
      "evaluating params={'learning_rate': 0.5607500300282854, 'depth': 5, 'l2_leaf_reg': 9.327068131764127, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                \n",
      "evaluated 15 times                                                                \n",
      "evaluating params={'learning_rate': 0.8379617890021351, 'depth': 2, 'l2_leaf_reg': 1.1914658620655203, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                 \n",
      "evaluated 16 times                                                                  \n",
      "evaluating params={'learning_rate': 0.7084504485390821, 'depth': 1, 'l2_leaf_reg': 8.77462819491742, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.6594692097881453                                                  \n",
      "evaluated 17 times                                                                  \n",
      "evaluating params={'learning_rate': 0.7765482036679838, 'depth': 4, 'l2_leaf_reg': 1.2270781826525714, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                  \n",
      "evaluated 18 times                                                                  \n",
      "evaluating params={'learning_rate': 0.4688598682627865, 'depth': 6, 'l2_leaf_reg': 6.426281836216337, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7589898297533878                                                  \n",
      "evaluated 19 times                                                                  \n",
      "evaluating params={'learning_rate': 0.9903819698303973, 'depth': 5, 'l2_leaf_reg': 1.109428741693996, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                  \n",
      "evaluated 20 times                                                                  \n",
      "evaluating params={'learning_rate': 0.36658391496240506, 'depth': 4, 'l2_leaf_reg': 4.777578117288439, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated score=0.7396890571420087                                                  \n",
      "evaluated 21 times                                                                  \n",
      "evaluating params={'learning_rate': 0.3548362548720143, 'depth': 6, 'l2_leaf_reg': 2.683829844728577, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.75898963971037                                                    \n",
      "evaluated 22 times                                                                  \n",
      "evaluating params={'learning_rate': 0.34157254294917927, 'depth': 2, 'l2_leaf_reg': 5.898356054606159, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                   \n",
      "evaluated 23 times                                                                  \n",
      "evaluating params={'learning_rate': 0.9527042409223028, 'depth': 6, 'l2_leaf_reg': 3.000062000817323, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.75898963971037                                                    \n",
      "evaluated 24 times                                                                  \n",
      "evaluating params={'learning_rate': 0.57241426529656, 'depth': 6, 'l2_leaf_reg': 6.7204797479586285, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7589898297533878                                                  \n",
      "evaluated 25 times                                                                  \n",
      "evaluating params={'learning_rate': 0.5211148575204896, 'depth': 5, 'l2_leaf_reg': 6.118464040111931, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                  \n",
      "evaluated 26 times                                                                  \n",
      "evaluating params={'learning_rate': 0.3399851604858861, 'depth': 4, 'l2_leaf_reg': 5.066001346551388, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                  \n",
      "evaluated 27 times                                                                  \n",
      "evaluating params={'learning_rate': 0.6644180708450913, 'depth': 4, 'l2_leaf_reg': 1.747360534815254, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                  \n",
      "evaluated 28 times                                                                  \n",
      "evaluating params={'learning_rate': 0.37265261187195214, 'depth': 6, 'l2_leaf_reg': 8.282932660961606, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7589904369127316                                                  \n",
      "evaluated 29 times                                                                  \n",
      "evaluating params={'learning_rate': 0.8067076288641906, 'depth': 6, 'l2_leaf_reg': 3.709621719662497, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.75898963971037                                                    \n",
      "evaluated 30 times                                                                  \n",
      "evaluating params={'learning_rate': 0.6180617022456502, 'depth': 3, 'l2_leaf_reg': 3.3693705779662446, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7191331646763076                                                  \n",
      "evaluated 31 times                                                                  \n",
      "evaluating params={'learning_rate': 0.4893315982302495, 'depth': 5, 'l2_leaf_reg': 6.819784684176986, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                  \n",
      "evaluated 32 times                                                                  \n",
      "evaluating params={'learning_rate': 0.5253981151450626, 'depth': 3, 'l2_leaf_reg': 5.22859499362952, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7191331646763076                                                  \n",
      "evaluated 33 times                                                                  \n",
      "evaluating params={'learning_rate': 0.3354257350958421, 'depth': 2, 'l2_leaf_reg': 2.689521777585739, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                   \n",
      "evaluated 34 times                                                                  \n",
      "evaluating params={'learning_rate': 0.4834378321016044, 'depth': 5, 'l2_leaf_reg': 6.683855423690435, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                  \n",
      "evaluated 35 times                                                                  \n",
      "evaluating params={'learning_rate': 0.3853308403799135, 'depth': 5, 'l2_leaf_reg': 1.3989575209747167, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                  \n",
      "evaluated 36 times                                                                  \n",
      "evaluating params={'learning_rate': 0.8179587704736393, 'depth': 2, 'l2_leaf_reg': 5.358056568243893, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                   \n",
      "evaluated 37 times                                                                  \n",
      "evaluating params={'learning_rate': 0.46070255062049537, 'depth': 0, 'l2_leaf_reg': 5.556613665141365, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.5                                                               \n",
      "evaluated 38 times                                                                \n",
      "evaluating params={'learning_rate': 0.54949744974684, 'depth': 3, 'l2_leaf_reg': 9.974148773979053, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7191331646763076                                                \n",
      "evaluated 39 times                                                                \n",
      "evaluating params={'learning_rate': 0.7142883739067785, 'depth': 4, 'l2_leaf_reg': 7.031708864638609, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                \n",
      "evaluated 40 times                                                                \n",
      "evaluating params={'learning_rate': 0.30934206926773045, 'depth': 6, 'l2_leaf_reg': 1.1340841931956307, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluated score=0.7589896416695763                                                \n",
      "evaluated 41 times                                                                \n",
      "evaluating params={'learning_rate': 0.5797660073534159, 'depth': 4, 'l2_leaf_reg': 7.441714806378932, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7396890571420087                                                \n",
      "evaluated 42 times                                                                \n",
      "evaluating params={'learning_rate': 0.7243213901349814, 'depth': 1, 'l2_leaf_reg': 8.562606711737995, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.6594692097881453                                                \n",
      "evaluated 43 times                                                                \n",
      "evaluating params={'learning_rate': 0.5475484910128263, 'depth': 5, 'l2_leaf_reg': 4.004641322081914, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                \n",
      "evaluated 44 times                                                                \n",
      "evaluating params={'learning_rate': 0.7187186975955295, 'depth': 1, 'l2_leaf_reg': 5.60356313930686, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.6594692097881453                                                \n",
      "evaluated 45 times                                                                \n",
      "evaluating params={'learning_rate': 0.7604556063823396, 'depth': 2, 'l2_leaf_reg': 8.244368650959261, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                 \n",
      "evaluated 46 times                                                                \n",
      "evaluating params={'learning_rate': 0.9386328062022089, 'depth': 5, 'l2_leaf_reg': 8.251862318697722, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                \n",
      "evaluated 47 times                                                                \n",
      "evaluating params={'learning_rate': 0.5822745819881355, 'depth': 2, 'l2_leaf_reg': 4.396290270801092, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.706028304452269                                                 \n",
      "evaluated 48 times                                                                \n",
      "evaluating params={'learning_rate': 0.22230774377542364, 'depth': 0, 'l2_leaf_reg': 2.9912426909623147, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.5                                                               \n",
      "evaluated 49 times                                                                \n",
      "evaluating params={'learning_rate': 0.3175378759429953, 'depth': 5, 'l2_leaf_reg': 3.54693788972967, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "evaluated score=0.7522499406851715                                                \n",
      "evaluated 50 times                                                                \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [3:37:07<00:00, 244.33s/it, best loss: -0.7589904369127316]\n",
      "best params are {'depth': 6, 'l2_leaf_reg': 8.282932660961606, 'learning_rate': 0.37265261187195214, 'task_type': 'CPU', 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'custom_metric': ['AUC'], 'iterations': 100, 'random_seed': 20181224}\n",
      "13070.273660898209\n"
     ]
    }
   ],
   "source": [
    "# make it True if your want to use GPU for training\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "have_gpu = False\n",
    "# skip hyper-parameter optimization and just use provided optimal parameters\n",
    "use_optimal_pretrained_params = False\n",
    "# number of iterations of hyper-parameter search\n",
    "hyperopt_iterations = 50\n",
    "\n",
    "const_params = frozendict({\n",
    "    'task_type': 'GPU' if have_gpu else 'CPU',\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC', \n",
    "    'custom_metric': ['AUC'],\n",
    "    'iterations': 100,\n",
    "    'random_seed': 20181224})\n",
    "\n",
    "model, params = train_best_model(\n",
    "    x_train, y_train, \n",
    "    const_params, \n",
    "    max_evals=hyperopt_iterations, \n",
    "    use_default=use_optimal_pretrained_params)\n",
    "print('best params are {}'.format(params), file=sys.stdout)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_on_dataset_and_show_graph(X, y, model):\n",
    "    import sklearn.metrics\n",
    "    import matplotlib.pylab as pl\n",
    "    pl.style.use('ggplot')\n",
    "    \n",
    "    dataset = cb.Pool(X, y, cat_features=categorical_features_indices)\n",
    "    fpr, tpr, _ = cbu.get_roc_curve(model, dataset)\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    \n",
    "    pl.figure(figsize=(8, 8,))\n",
    "    pl.plot(fpr, tpr)\n",
    "    pl.xlim([-0.1, 1.1])\n",
    "    pl.ylim([-0.1, 1.1])\n",
    "    pl.xlabel('FPR')\n",
    "    pl.ylabel('TPR')\n",
    "    pl.title('ROC curve (AUC={:.3f})'.format(auc))\n",
    "    pl.show()\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35820914 0.64179086]\n",
      " [0.26202473 0.73797527]\n",
      " [0.71506544 0.28493456]\n",
      " [0.2532457  0.7467543 ]\n",
      " [0.32070098 0.67929902]\n",
      " [0.6204458  0.3795542 ]\n",
      " [0.31330456 0.68669544]\n",
      " [0.5294793  0.4705207 ]\n",
      " [0.38318251 0.61681749]\n",
      " [0.81924206 0.18075794]\n",
      " [0.9182941  0.0817059 ]\n",
      " [0.21227542 0.78772458]\n",
      " [0.22267179 0.77732821]\n",
      " [0.91485656 0.08514344]\n",
      " [0.25987947 0.74012053]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Below- Compute & display sample of class probabilities for test feature data set.\n",
    " # Class w/ highest probability is taken as score (prediction)\n",
    "    \n",
    "probabilities = model.predict_proba(data=x_validation)\n",
    "print(probabilities[:15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 0 1 0 0 1 1 0 1]\n",
      "[0 0 1 0 1 0 1 0 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Above- 1st column= probability of score 0, 2nd column= prob of score 1.\n",
    "\n",
    "#Below- Transform class probabilities into class scores.\n",
    " # Set threshold to prob b/w 2 likelihoods at 0.5. This is applied to prob of score 0 below.\n",
    "    \n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x> threshold else 0 for x in probs[:, 1]])\n",
    "scores = score_model(probabilities, 0.5)\n",
    "print(np.array(scores[:15]))\n",
    "print(y_validation[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n",
      "0.7226133333333333\n"
     ]
    }
   ],
   "source": [
    "# ReCheck accuracy by the equal provided by DrivenData\n",
    "\n",
    "N = len(y_validation)\n",
    "print(N)\n",
    "\n",
    "def isEqual(a):\n",
    "    return a[0] == a[1]\n",
    "\n",
    "ClRt = (1/N)*sum(1 for i in filter(isEqual, zip(scores, y_validation)))\n",
    "print(ClRt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion Matrix \n",
      "                 Score Positive     Score Negative \n",
      "Actual Positive     49746              25208\n",
      "Actual Negative     16400              58646\n",
      "\n",
      "Accuracy   0.72\n",
      "\n",
      "            Positive     Negative\n",
      "Num Case     74954         75046\n",
      "Precision     0.75          0.70\n",
      "Recall        0.66          0.78\n",
      "F1            0.71          0.71\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sklm\n",
    "\n",
    "#Below- Compute a confusion matrix as a metric to evaluate the results for the logisitic regression model\n",
    " #True Positive (TP)- cases w/ positive labels which have been correctly classified as positive\n",
    " #True Negative (TN)- cases w/ negative labels which have been correctly classified as negative\n",
    " #False Positive (FP)- cases w/ negative labels which have been incorrectly classified as positive\n",
    " #False Negative (FN)- cases w/ positive labels which have been incorrectly classified as negative\n",
    " # where positive is 1 and neagtive is 0\n",
    "    \n",
    " #Accuracy/Bias- fraction of cases correctly classified\n",
    " #Precision- fraction of correctly calssified label cases out of all cases classified w/ that label value\n",
    "   # is sentistive to the # of cases correctly classified for a given score value\n",
    " #Recall- fraction of cases of a label value correctly classified out of all cases for that have that label value\n",
    "   # is sensitive to the # of cases correctly classified for a given true label value\n",
    " #F1- weighted average of precision and recall (overall model performance)\n",
    " #ROC- (receiver operating characteristic) displays relationship b/w TP rate on y and FP rate on x\n",
    " #AUC- (area/integral under the curve) overall performance of classifer model\n",
    "   # higher the AUC, the lower the increase in FP rate req to achieve a req TP rate\n",
    "     # Ideally AUC= 1.0, TP rate is achieved w/ 0 FP rate.\n",
    "     # can compare classifiers, one w/ higher AUC is generally better\n",
    "     # ROC diagonal for Bernoulli w/ AUC 0.5, anything greater than this is better than random guessing in balanced cases\n",
    "    \n",
    "#Below- Compute & examine the performance metrics for the classifier using precision_recall_fscore_support \n",
    " # & accuracy_score functions from metric package in scikit-learn. Confusion matrix is computed through \n",
    " # confusion_matrix from same package.\n",
    "\n",
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix ')\n",
    "    print('                 Score Positive     Score Negative ')\n",
    "    print('Actual Positive    %6d' % conf[0, 0] + '              %5d' % conf[0, 1])\n",
    "    print('Actual Negative    %6d' % conf[1, 0] + '              %5d' % conf[1, 1])\n",
    "    print('')\n",
    "    print('Accuracy   %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('')\n",
    "    print('            Positive     Negative')\n",
    "    print('Num Case    %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision   %6.2f' % metrics[0][0] + '        %6.2f' % metrics [0][1])\n",
    "    print('Recall      %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1          %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][0])\n",
    "    \n",
    "    \n",
    "print_metrics(y_validation, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7c4d62574e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check probabilities for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Check probabilities for predictions\n",
    "\n",
    "print(model.predict_proba(data=x_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-25ccb78ed53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check scores for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Check scores for predictions\n",
    "\n",
    "print(model.predict(data=x_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PREDICT = model.predict(data=x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PREDICT_df = pd.DataFrame(Y_PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to csv for submission\n",
    "\n",
    "Y_PREDICT_df.to_csv('results/results_2019-08-15.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Importances\n",
    "\n",
    "model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score & display performance metrics for test dataset model\n",
    "\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion Matrix')\n",
    "    print('                 Score Positive    Score Negative')\n",
    "    print('Actual Positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual Negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro Precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro Recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num Case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = model.predict_proba(x_validation)\n",
    "print_metrics(y_validation, probabilities, 0.5)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
